{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T04:57:02.635811Z","iopub.execute_input":"2023-12-28T04:57:02.636269Z","iopub.status.idle":"2023-12-28T04:57:02.646892Z","shell.execute_reply.started":"2023-12-28T04:57:02.636222Z","shell.execute_reply":"2023-12-28T04:57:02.645460Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imports dependencies","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nprint (tfdf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.653549Z","iopub.execute_input":"2023-12-28T04:57:02.654024Z","iopub.status.idle":"2023-12-28T04:57:02.663079Z","shell.execute_reply.started":"2023-12-28T04:57:02.653983Z","shell.execute_reply":"2023-12-28T04:57:02.661767Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stdout","text":"1.5.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nserving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntrain_df.head(10)\nprint(train_df.shape)\nprint(serving_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.664875Z","iopub.execute_input":"2023-12-28T04:57:02.665432Z","iopub.status.idle":"2023-12-28T04:57:02.688955Z","shell.execute_reply.started":"2023-12-28T04:57:02.665396Z","shell.execute_reply":"2023-12-28T04:57:02.687823Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"(891, 12)\n(418, 11)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare dataset","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n        \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\npreprocessed_training_def = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\npreprocessed_training_def.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.691879Z","iopub.execute_input":"2023-12-28T04:57:02.693208Z","iopub.status.idle":"2023-12-28T04:57:02.737378Z","shell.execute_reply.started":"2023-12-28T04:57:02.693152Z","shell.execute_reply":"2023-12-28T04:57:02.735955Z"},"trusted":true},"execution_count":147,"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                              Name     Sex   Age  SibSp  \\\n0                            Braund Mr Owen Harris    male  22.0      1   \n1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                             Heikkinen Miss Laina  female  26.0      0   \n3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                           Allen Mr William Henry    male  35.0      0   \n5                                   Moran Mr James    male   NaN      0   \n6                            McCarthy Mr Timothy J    male  54.0      0   \n7                     Palsson Master Gosta Leonard    male   2.0      3   \n8    Johnson Mrs Oscar W Elisabeth Vilhelmina Berg  female  27.0      0   \n9                  Nasser Mrs Nicholas Adele Achem  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1      0          PC 17599  71.2833   C85        C         17599          PC  \n2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3      0            113803  53.1000  C123        S        113803        NONE  \n4      0            373450   8.0500   NaN        S        373450        NONE  \n5      0            330877   8.4583   NaN        Q        330877        NONE  \n6      0             17463  51.8625   E46        S         17463        NONE  \n7      1            349909  21.0750   NaN        S        349909        NONE  \n8      2            347742  11.1333   NaN        S        347742        NONE  \n9      0            237736  30.0708   NaN        C        237736        NONE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_number</th>\n      <th>Ticket_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran Mr James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>330877</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy Mr Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n      <td>17463</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson Master Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>349909</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson Mrs Oscar W Elisabeth Vilhelmina Berg</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>347742</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser Mrs Nicholas Adele Achem</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>237736</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"input_features = list(preprocessed_training_def.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n\nprint(f\"input featurs {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.739907Z","iopub.execute_input":"2023-12-28T04:57:02.740439Z","iopub.status.idle":"2023-12-28T04:57:02.749386Z","shell.execute_reply.started":"2023-12-28T04:57:02.740388Z","shell.execute_reply":"2023-12-28T04:57:02.747516Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stdout","text":"input featurs ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Convert Pandas dataframe to TensorFlow Dataset","metadata":{}},{"cell_type":"code","source":"def Tokenize_names(features,labels = None):\n    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n    return features, labels\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def,label=\"Survived\").map(Tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(Tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.751597Z","iopub.execute_input":"2023-12-28T04:57:02.752209Z","iopub.status.idle":"2023-12-28T04:57:02.934530Z","shell.execute_reply.started":"2023-12-28T04:57:02.752155Z","shell.execute_reply":"2023-12-28T04:57:02.933107Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"# Train a model with default parameters\n","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0,\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features = True,\n    random_seed=3116,\n)\nmodel.fit(train_ds)\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy : {self_evaluation.accuracy} Loss : {self_evaluation.loss} \")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.937532Z","iopub.execute_input":"2023-12-28T04:57:02.937913Z","iopub.status.idle":"2023-12-28T04:57:04.099464Z","shell.execute_reply.started":"2023-12-28T04:57:02.937879Z","shell.execute_reply":"2023-12-28T04:57:04.097471Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stderr","text":"[WARNING 23-12-28 04:57:02.9547 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 04:57:02.9548 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 04:57:02.9548 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 23-12-28 04:57:03.7033 UTC kernel.cc:1243] Loading model from path /tmp/tmpz11cmdd3/model/ with prefix 8368636617024c4b\n[INFO 23-12-28 04:57:03.7107 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n[INFO 23-12-28 04:57:03.7107 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy : 0.8125 Loss : 0.8233121633529663 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train model with improved default parameters","metadata":{}},{"cell_type":"code","source":"model2 = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    \n    #num_trees=2000,\n    \n    # Only for GBT.\n    # A bit slower, but great to understand the model.\n    # compute_permutation_variable_importance=True,\n    \n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n    \n    min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n    sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234,\n    \n)\nmodel2.fit(train_ds)\n\nself_evaluation = model2.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:04.101307Z","iopub.execute_input":"2023-12-28T04:57:04.101785Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"[WARNING 23-12-28 04:57:04.1241 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 04:57:04.1243 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 04:57:04.1245 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n","output_type":"stream"}]},{"cell_type":"code","source":"model2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make predictions","metadata":{}},{"cell_type":"markdown","source":"some debugging here","metadata":{}},{"cell_type":"code","source":"# #train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def,label=\"Survived\").map(Tokenize_names)\n# #serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def).map(Tokenize_names)\n# serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(Tokenize_names)\n# proba_survived = model2.predict(serving_ds, verbose=0)\n# print(f\"proba survived shape : {proba_survived.shape}\")\n# proba_survived = proba_survived[:,0]\n# print(f\"proba survived shape : {proba_survived.shape}\")\n# print(f\"serving df shape : {serving_df.shape}\")\n# print(f\"serving df shape : {serving_ds.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_to_kaggle_format(model, treshold = 0.5):\n    proba_survived = model.predict(serving_ds, verbose=0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\" : serving_df[\"PassengerId\"].values,\n        \"Survived\" : (proba_survived >= treshold).astype(int)\n    })\n\ndef make_submission(kaggle_predictions):\n    path = \"/kaggle/working/submission.csv\"\n    kaggle_predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n    \nkaggle_predictions = prediction_to_kaggle_format(model)\nmake_submission(kaggle_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head /kaggle/working/submission.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training a model with hyperparameter tunning","metadata":{}},{"cell_type":"code","source":"tuner = tfdf.tuner.RandomSearch(num_trials=1000)\ntuner.choice(\"min_examples\", [2, 5, 7, 10])\ntuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n\nlocal_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\nlocal_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n\nglobal_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\nglobal_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n\ntuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\ntuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n\ntuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\noblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\noblique_space.choice(\"sparse_oblique_normalization\",[\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n\noblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\noblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n\n\ntuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\ntuned_model.fit(train_ds, verbose=0)\n\ntuned_self_evaluation = tuned_model.make_inspector().evaluation()\nprint(f\"Accuracy {tuned_self_evaluation.accuracy}, Loss {tuned_self_evaluation.loss} \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making an ensemble","metadata":{}},{"cell_type":"code","source":"predictions = 0\nnum_predictions = 0\n\nfor i in range (100):\n    print(f\"i: {i}\")\n    model = tfdf.keras.GradientBoostedTreesModel(\n        verbose = 0,\n        features = [tfdf.keras.FeatureUsage(name = n) for n in input_features],\n        exclude_non_specified_features = True,\n        random_seed=i,\n        honest=True\n    )\n    model.fit(train_ds)\n    sub_predictions = model.predict(serving_ds, verbose=0)[:,0]\n    if predictions is None:\n        predictions += sub_predictions\n    else:\n        predictions += sub_predictions\n    num_predictions += 1\n    \npredictions /= num_predictions\nkaggle_predictions = pd.DataFrame({\n    \"PassengerId\":serving_df[\"PassengerId\"],\n    \"Survived\":(predictions >= 0.5).astype(int)\n})\nmake_submission(kaggle_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}