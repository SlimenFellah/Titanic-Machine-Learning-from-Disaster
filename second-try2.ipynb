{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T04:57:02.635811Z","iopub.execute_input":"2023-12-28T04:57:02.636269Z","iopub.status.idle":"2023-12-28T04:57:02.646892Z","shell.execute_reply.started":"2023-12-28T04:57:02.636222Z","shell.execute_reply":"2023-12-28T04:57:02.645460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports dependencies","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nprint (tfdf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.653549Z","iopub.execute_input":"2023-12-28T04:57:02.654024Z","iopub.status.idle":"2023-12-28T04:57:02.663079Z","shell.execute_reply.started":"2023-12-28T04:57:02.653983Z","shell.execute_reply":"2023-12-28T04:57:02.661767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nserving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntrain_df.head(10)\nprint(train_df.shape)\nprint(serving_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.664875Z","iopub.execute_input":"2023-12-28T04:57:02.665432Z","iopub.status.idle":"2023-12-28T04:57:02.688955Z","shell.execute_reply.started":"2023-12-28T04:57:02.665396Z","shell.execute_reply":"2023-12-28T04:57:02.687823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare dataset","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n        \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\npreprocessed_training_def = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\npreprocessed_training_def.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.691879Z","iopub.execute_input":"2023-12-28T04:57:02.693208Z","iopub.status.idle":"2023-12-28T04:57:02.737378Z","shell.execute_reply.started":"2023-12-28T04:57:02.693152Z","shell.execute_reply":"2023-12-28T04:57:02.735955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_features = list(preprocessed_training_def.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n\nprint(f\"input featurs {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.739907Z","iopub.execute_input":"2023-12-28T04:57:02.740439Z","iopub.status.idle":"2023-12-28T04:57:02.749386Z","shell.execute_reply.started":"2023-12-28T04:57:02.740388Z","shell.execute_reply":"2023-12-28T04:57:02.747516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Pandas dataframe to TensorFlow Dataset","metadata":{}},{"cell_type":"code","source":"def Tokenize_names(features,labels = None):\n    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n    return features, labels\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def,label=\"Survived\").map(Tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(Tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.751597Z","iopub.execute_input":"2023-12-28T04:57:02.752209Z","iopub.status.idle":"2023-12-28T04:57:02.934530Z","shell.execute_reply.started":"2023-12-28T04:57:02.752155Z","shell.execute_reply":"2023-12-28T04:57:02.933107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train a model with default parameters\n","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0,\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features = True,\n    random_seed=3116,\n)\nmodel.fit(train_ds)\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy : {self_evaluation.accuracy} Loss : {self_evaluation.loss} \")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:02.937532Z","iopub.execute_input":"2023-12-28T04:57:02.937913Z","iopub.status.idle":"2023-12-28T04:57:04.099464Z","shell.execute_reply.started":"2023-12-28T04:57:02.937879Z","shell.execute_reply":"2023-12-28T04:57:04.097471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model with improved default parameters","metadata":{}},{"cell_type":"code","source":"model2 = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    \n    #num_trees=2000,\n    \n    # Only for GBT.\n    # A bit slower, but great to understand the model.\n    # compute_permutation_variable_importance=True,\n    \n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n    \n    min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n    sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234,\n    \n)\nmodel2.fit(train_ds)\n\nself_evaluation = model2.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:57:04.101307Z","iopub.execute_input":"2023-12-28T04:57:04.101785Z","iopub.status.idle":"2023-12-28T04:58:03.364733Z","shell.execute_reply.started":"2023-12-28T04:57:04.101737Z","shell.execute_reply":"2023-12-28T04:58:03.363598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:58:03.366118Z","iopub.execute_input":"2023-12-28T04:58:03.366547Z","iopub.status.idle":"2023-12-28T04:58:03.384161Z","shell.execute_reply.started":"2023-12-28T04:58:03.366511Z","shell.execute_reply":"2023-12-28T04:58:03.382696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make predictions","metadata":{}},{"cell_type":"markdown","source":"some debugging here","metadata":{}},{"cell_type":"code","source":"# #train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def,label=\"Survived\").map(Tokenize_names)\n# #serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def).map(Tokenize_names)\n# serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(Tokenize_names)\n# proba_survived = model2.predict(serving_ds, verbose=0)\n# print(f\"proba survived shape : {proba_survived.shape}\")\n# proba_survived = proba_survived[:,0]\n# print(f\"proba survived shape : {proba_survived.shape}\")\n# print(f\"serving df shape : {serving_df.shape}\")\n# print(f\"serving df shape : {serving_ds.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:58:03.385573Z","iopub.execute_input":"2023-12-28T04:58:03.385917Z","iopub.status.idle":"2023-12-28T04:58:03.392815Z","shell.execute_reply.started":"2023-12-28T04:58:03.385879Z","shell.execute_reply":"2023-12-28T04:58:03.391855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_to_kaggle_format(model, treshold = 0.5):\n    proba_survived = model.predict(serving_ds, verbose=0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\" : serving_df[\"PassengerId\"].values,\n        \"Survived\" : (proba_survived >= treshold).astype(int)\n    })\n\ndef make_submission(kaggle_predictions):\n    path = \"/kaggle/working/submission.csv\"\n    kaggle_predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n    \nkaggle_predictions = prediction_to_kaggle_format(model)\nmake_submission(kaggle_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:58:03.393903Z","iopub.execute_input":"2023-12-28T04:58:03.394266Z","iopub.status.idle":"2023-12-28T04:58:03.591330Z","shell.execute_reply.started":"2023-12-28T04:58:03.394217Z","shell.execute_reply":"2023-12-28T04:58:03.590034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head /kaggle/working/submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:58:03.594987Z","iopub.execute_input":"2023-12-28T04:58:03.595644Z","iopub.status.idle":"2023-12-28T04:58:04.771377Z","shell.execute_reply.started":"2023-12-28T04:58:03.595589Z","shell.execute_reply":"2023-12-28T04:58:04.769728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training a model with hyperparameter tunning","metadata":{}},{"cell_type":"code","source":"tuner = tfdf.tuner.RandomSearch(num_trials=1000)\ntuner.choice(\"min_examples\", [2, 5, 7, 10])\ntuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n\nlocal_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\nlocal_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n\nglobal_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\nglobal_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n\ntuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\ntuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n\ntuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\noblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\noblique_space.choice(\"sparse_oblique_normalization\",[\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\n\noblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\noblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n\n\ntuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\ntuned_model.fit(train_ds, verbose=0)\n\ntuned_self_evaluation = tuned_model.make_inspector().evaluation()\nprint(f\"Accuracy {tuned_self_evaluation.accuracy}, Loss {tuned_self_evaluation.loss} \")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:58:04.773886Z","iopub.execute_input":"2023-12-28T04:58:04.775105Z","iopub.status.idle":"2023-12-28T05:00:27.220541Z","shell.execute_reply.started":"2023-12-28T04:58:04.775062Z","shell.execute_reply":"2023-12-28T05:00:27.219063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making an ensemble","metadata":{}},{"cell_type":"code","source":"predictions = 0\nnum_predictions = 0\n\nfor i in range (100):\n    print(f\"i: {i}\")\n    model = tfdf.keras.GradientBoostedTreesModel(\n        verbose = 0,\n        features = [tfdf.keras.FeatureUsage(name = n) for n in input_features],\n        exclude_non_specified_features = True,\n        random_seed=i,\n        honest=True\n    )\n    model.fit(train_ds)\n    sub_predictions = model.predict(serving_ds, verbose=0)[:,0]\n    if predictions is None:\n        predictions += sub_predictions\n    else:\n        predictions += sub_predictions\n    num_predictions += 1\n    \npredictions /= num_predictions\nkaggle_predictions = pd.DataFrame({\n    \"PassengerId\":serving_df[\"PassengerId\"],\n    \"Survived\":(predictions >= 0.5).astype(int)\n})\nmake_submission(kaggle_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T05:00:27.221948Z","iopub.execute_input":"2023-12-28T05:00:27.222331Z","iopub.status.idle":"2023-12-28T05:02:51.270971Z","shell.execute_reply.started":"2023-12-28T05:00:27.222287Z","shell.execute_reply":"2023-12-28T05:02:51.269103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}