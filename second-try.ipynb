{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T03:13:42.109973Z","iopub.execute_input":"2023-12-28T03:13:42.110370Z","iopub.status.idle":"2023-12-28T03:13:42.120605Z","shell.execute_reply.started":"2023-12-28T03:13:42.110336Z","shell.execute_reply":"2023-12-28T03:13:42.119137Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imports dependencies","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nprint (tfdf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:13:42.440399Z","iopub.execute_input":"2023-12-28T03:13:42.441068Z","iopub.status.idle":"2023-12-28T03:13:42.447095Z","shell.execute_reply.started":"2023-12-28T03:13:42.441030Z","shell.execute_reply":"2023-12-28T03:13:42.445939Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"1.5.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nserving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntrain_df.head(10)\nprint(train_df.shape)\nprint(serving_df.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:24:19.230307Z","iopub.execute_input":"2023-12-28T03:24:19.230724Z","iopub.status.idle":"2023-12-28T03:24:19.250842Z","shell.execute_reply.started":"2023-12-28T03:24:19.230688Z","shell.execute_reply":"2023-12-28T03:24:19.249386Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"(891, 12)\n(418, 11)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare dataset","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n        \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\npreprocessed_training_def = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\npreprocessed_training_def.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:21:36.061081Z","iopub.execute_input":"2023-12-28T03:21:36.061562Z","iopub.status.idle":"2023-12-28T03:21:36.099443Z","shell.execute_reply.started":"2023-12-28T03:21:36.061524Z","shell.execute_reply":"2023-12-28T03:21:36.098138Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                              Name     Sex   Age  SibSp  \\\n0                            Braund Mr Owen Harris    male  22.0      1   \n1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                             Heikkinen Miss Laina  female  26.0      0   \n3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                           Allen Mr William Henry    male  35.0      0   \n5                                   Moran Mr James    male   NaN      0   \n6                            McCarthy Mr Timothy J    male  54.0      0   \n7                     Palsson Master Gosta Leonard    male   2.0      3   \n8    Johnson Mrs Oscar W Elisabeth Vilhelmina Berg  female  27.0      0   \n9                  Nasser Mrs Nicholas Adele Achem  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1      0          PC 17599  71.2833   C85        C         17599          PC  \n2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3      0            113803  53.1000  C123        S        113803        NONE  \n4      0            373450   8.0500   NaN        S        373450        NONE  \n5      0            330877   8.4583   NaN        Q        330877        NONE  \n6      0             17463  51.8625   E46        S         17463        NONE  \n7      1            349909  21.0750   NaN        S        349909        NONE  \n8      2            347742  11.1333   NaN        S        347742        NONE  \n9      0            237736  30.0708   NaN        C        237736        NONE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_number</th>\n      <th>Ticket_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran Mr James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>330877</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy Mr Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n      <td>17463</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson Master Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>349909</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson Mrs Oscar W Elisabeth Vilhelmina Berg</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>347742</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser Mrs Nicholas Adele Achem</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>237736</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"input_features = list(preprocessed_training_def.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n\nprint(f\"input featurs {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:21:39.743917Z","iopub.execute_input":"2023-12-28T03:21:39.744339Z","iopub.status.idle":"2023-12-28T03:21:39.752867Z","shell.execute_reply.started":"2023-12-28T03:21:39.744300Z","shell.execute_reply":"2023-12-28T03:21:39.751338Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"input featurs ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Convert Pandas dataframe to TensorFlow Dataset","metadata":{}},{"cell_type":"code","source":"def Tokenize_names(features,labels = None):\n    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n    return features, labels\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def,label=\"Survived\").map(Tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(Tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:31:01.318790Z","iopub.execute_input":"2023-12-28T03:31:01.319330Z","iopub.status.idle":"2023-12-28T03:31:01.481288Z","shell.execute_reply.started":"2023-12-28T03:31:01.319292Z","shell.execute_reply":"2023-12-28T03:31:01.479991Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# Train a model with default parameters\n","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0,\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features = True,\n    random_seed=3116,\n)\nmodel.fit(train_ds)\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy : {self_evaluation.accuracy} Loss : {self_evaluation.loss} \")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:21:43.752754Z","iopub.execute_input":"2023-12-28T03:21:43.753517Z","iopub.status.idle":"2023-12-28T03:21:45.402411Z","shell.execute_reply.started":"2023-12-28T03:21:43.753478Z","shell.execute_reply":"2023-12-28T03:21:45.401266Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"[WARNING 23-12-28 03:21:43.7658 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 03:21:43.7659 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 03:21:43.7659 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 23-12-28 03:21:44.5045 UTC kernel.cc:1243] Loading model from path /tmp/tmp91ip7guu/model/ with prefix 88780e9d4c2146e9\n[INFO 23-12-28 03:21:44.5117 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n[INFO 23-12-28 03:21:44.5117 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy : 0.8125 Loss : 0.8233121633529663 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train model with improved default parameters","metadata":{}},{"cell_type":"code","source":"model2 = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    \n    #num_trees=2000,\n    \n    # Only for GBT.\n    # A bit slower, but great to understand the model.\n    # compute_permutation_variable_importance=True,\n    \n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n    \n    min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n    sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234,\n    \n)\nmodel2.fit(train_ds)\n\nself_evaluation = model2.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:42:45.019278Z","iopub.execute_input":"2023-12-28T03:42:45.019709Z","iopub.status.idle":"2023-12-28T03:42:46.446856Z","shell.execute_reply.started":"2023-12-28T03:42:45.019675Z","shell.execute_reply":"2023-12-28T03:42:46.445541Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"[WARNING 23-12-28 03:42:45.0351 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 03:42:45.0351 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-12-28 03:42:45.0352 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 23-12-28 03:42:46.0835 UTC kernel.cc:1243] Loading model from path /tmp/tmpfe2y31n7/model/ with prefix 843b8a9399b844b3\n[INFO 23-12-28 03:42:46.0941 UTC decision_forest.cc:660] Model loaded with 42 root(s), 2212 node(s), and 10 input feature(s).\n[INFO 23-12-28 03:42:46.0943 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.782608687877655 Loss:1.060815453529358\n","output_type":"stream"}]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:42:47.733297Z","iopub.execute_input":"2023-12-28T03:42:47.733682Z","iopub.status.idle":"2023-12-28T03:42:47.751288Z","shell.execute_reply.started":"2023-12-28T03:42:47.733649Z","shell.execute_reply":"2023-12-28T03:42:47.750102Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Model: \"gradient_boosted_trees_model_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n=================================================================\nTotal params: 1 (1.00 Byte)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 1 (1.00 Byte)\n_________________________________________________________________\nType: \"GRADIENT_BOOSTED_TREES\"\nTask: CLASSIFICATION\nLabel: \"__LABEL\"\n\nInput Features (11):\n\tAge\n\tCabin\n\tEmbarked\n\tFare\n\tName\n\tParch\n\tPclass\n\tSex\n\tSibSp\n\tTicket_item\n\tTicket_number\n\nNo weights\n\nVariable Importance: INV_MEAN_MIN_DEPTH:\n    1.           \"Sex\"  0.597073 ################\n    2.           \"Age\"  0.363764 #######\n    3.          \"Fare\"  0.264018 ###\n    4.          \"Name\"  0.207843 #\n    5.        \"Pclass\"  0.178906 \n    6. \"Ticket_number\"  0.178488 \n    7.   \"Ticket_item\"  0.177907 \n    8.      \"Embarked\"  0.177237 \n    9.         \"Parch\"  0.175481 \n   10.         \"SibSp\"  0.171800 \n\nVariable Importance: NUM_AS_ROOT:\n    1.  \"Sex\" 36.000000 ################\n    2. \"Name\"  6.000000 \n\nVariable Importance: NUM_NODES:\n    1.           \"Age\" 530.000000 ################\n    2.          \"Fare\" 311.000000 #########\n    3.          \"Name\" 66.000000 #\n    4.   \"Ticket_item\" 50.000000 #\n    5.           \"Sex\" 42.000000 #\n    6.         \"Parch\" 26.000000 \n    7. \"Ticket_number\" 21.000000 \n    8.        \"Pclass\" 17.000000 \n    9.      \"Embarked\" 16.000000 \n   10.         \"SibSp\"  6.000000 \n\nVariable Importance: SUM_SCORE:\n    1.           \"Sex\" 484.272240 ################\n    2.           \"Age\" 393.999352 #############\n    3.          \"Fare\" 323.250985 ##########\n    4.          \"Name\" 105.330212 ###\n    5.        \"Pclass\" 26.851849 \n    6.   \"Ticket_item\" 25.837695 \n    7. \"Ticket_number\" 17.652836 \n    8.      \"Embarked\"  9.217001 \n    9.         \"Parch\"  7.010211 \n   10.         \"SibSp\"  0.574055 \n\n\n\nLoss: BINOMIAL_LOG_LIKELIHOOD\nValidation loss value: 1.06082\nNumber of trees per iteration: 1\nNode format: NOT_SET\nNumber of trees: 42\nTotal number of nodes: 2212\n\nNumber of nodes by tree:\nCount: 42 Average: 52.6667 StdDev: 4.47036\nMin: 41 Max: 63 Ignored: 0\n----------------------------------------------\n[ 41, 42)  2   4.76%   4.76% ##\n[ 42, 43)  0   0.00%   4.76%\n[ 43, 44)  0   0.00%   4.76%\n[ 44, 45)  0   0.00%   4.76%\n[ 45, 46)  1   2.38%   7.14% #\n[ 46, 47)  0   0.00%   7.14%\n[ 47, 49)  2   4.76%  11.90% ##\n[ 49, 50)  5  11.90%  23.81% ####\n[ 50, 51)  0   0.00%  23.81%\n[ 51, 52)  4   9.52%  33.33% ###\n[ 52, 53)  0   0.00%  33.33%\n[ 53, 54) 13  30.95%  64.29% ##########\n[ 54, 55)  0   0.00%  64.29%\n[ 55, 57)  9  21.43%  85.71% #######\n[ 57, 58)  1   2.38%  88.10% #\n[ 58, 59)  0   0.00%  88.10%\n[ 59, 60)  3   7.14%  95.24% ##\n[ 60, 61)  0   0.00%  95.24%\n[ 61, 62)  1   2.38%  97.62% #\n[ 62, 63]  1   2.38% 100.00% #\n\nDepth by leafs:\nCount: 1127 Average: 4.8465 StdDev: 0.454147\nMin: 2 Max: 5 Ignored: 0\n----------------------------------------------\n[ 2, 3)   1   0.09%   0.09%\n[ 3, 4)  40   3.55%   3.64%\n[ 4, 5)  90   7.99%  11.62% #\n[ 5, 5] 996  88.38% 100.00% ##########\n\nNumber of training obs by leaf:\nCount: 1127 Average: 29.7764 StdDev: 71.9364\nMin: 1 Max: 467 Ignored: 0\n----------------------------------------------\n[   1,  24) 884  78.44%  78.44% ##########\n[  24,  47)  79   7.01%  85.45% #\n[  47,  71)  44   3.90%  89.35%\n[  71,  94)  19   1.69%  91.04%\n[  94, 117)  13   1.15%  92.19%\n[ 117, 141)  15   1.33%  93.52%\n[ 141, 164)  24   2.13%  95.65%\n[ 164, 187)   6   0.53%  96.18%\n[ 187, 211)   4   0.35%  96.54%\n[ 211, 234)   1   0.09%  96.63%\n[ 234, 257)   1   0.09%  96.72%\n[ 257, 281)   3   0.27%  96.98%\n[ 281, 304)   2   0.18%  97.16%\n[ 304, 327)   2   0.18%  97.34%\n[ 327, 351)   2   0.18%  97.52%\n[ 351, 374)  11   0.98%  98.49%\n[ 374, 397)   5   0.44%  98.94%\n[ 397, 421)   9   0.80%  99.73%\n[ 421, 444)   1   0.09%  99.82%\n[ 444, 467]   2   0.18% 100.00%\n\nAttribute in nodes:\n\t530 : Age [NUMERICAL]\n\t311 : Fare [NUMERICAL]\n\t66 : Name [CATEGORICAL_SET]\n\t50 : Ticket_item [CATEGORICAL]\n\t42 : Sex [CATEGORICAL]\n\t26 : Parch [NUMERICAL]\n\t21 : Ticket_number [CATEGORICAL]\n\t17 : Pclass [NUMERICAL]\n\t16 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 0:\n\t36 : Sex [CATEGORICAL]\n\t6 : Name [CATEGORICAL_SET]\n\nAttribute in nodes with depth <= 1:\n\t50 : Age [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t26 : Fare [NUMERICAL]\n\t7 : Name [CATEGORICAL_SET]\n\t5 : Pclass [NUMERICAL]\n\t2 : Ticket_number [CATEGORICAL]\n\nAttribute in nodes with depth <= 2:\n\t130 : Age [NUMERICAL]\n\t76 : Fare [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t19 : Name [CATEGORICAL_SET]\n\t8 : Ticket_number [CATEGORICAL]\n\t7 : Embarked [CATEGORICAL]\n\t6 : Pclass [NUMERICAL]\n\t6 : Parch [NUMERICAL]\n\t5 : Ticket_item [CATEGORICAL]\n\nAttribute in nodes with depth <= 3:\n\t270 : Age [NUMERICAL]\n\t173 : Fare [NUMERICAL]\n\t39 : Name [CATEGORICAL_SET]\n\t38 : Sex [CATEGORICAL]\n\t18 : Ticket_item [CATEGORICAL]\n\t13 : Ticket_number [CATEGORICAL]\n\t12 : Parch [NUMERICAL]\n\t12 : Embarked [CATEGORICAL]\n\t9 : Pclass [NUMERICAL]\n\t3 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 5:\n\t530 : Age [NUMERICAL]\n\t311 : Fare [NUMERICAL]\n\t66 : Name [CATEGORICAL_SET]\n\t50 : Ticket_item [CATEGORICAL]\n\t42 : Sex [CATEGORICAL]\n\t26 : Parch [NUMERICAL]\n\t21 : Ticket_number [CATEGORICAL]\n\t17 : Pclass [NUMERICAL]\n\t16 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nCondition type in nodes:\n\t890 : ObliqueCondition\n\t145 : ContainsBitmapCondition\n\t50 : ContainsCondition\nCondition type in nodes with depth <= 0:\n\t40 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 1:\n\t81 : ObliqueCondition\n\t43 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 2:\n\t218 : ObliqueCondition\n\t62 : ContainsBitmapCondition\n\t13 : ContainsCondition\nCondition type in nodes with depth <= 3:\n\t467 : ObliqueCondition\n\t89 : ContainsBitmapCondition\n\t31 : ContainsCondition\nCondition type in nodes with depth <= 5:\n\t890 : ObliqueCondition\n\t145 : ContainsBitmapCondition\n\t50 : ContainsCondition\n\nTraining logs:\nNumber of iteration to final model: 42\n\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n\tIter:26 train-loss:0.648139 valid-loss:1.066864  train-accuracy:0.921151 valid-accuracy:0.782609\n\tIter:36 train-loss:0.559101 valid-loss:1.068122  train-accuracy:0.921151 valid-accuracy:0.782609\n\tIter:46 train-loss:0.496837 valid-loss:1.064204  train-accuracy:0.929912 valid-accuracy:0.771739\n\tIter:56 train-loss:0.451017 valid-loss:1.083011  train-accuracy:0.941176 valid-accuracy:0.771739\n\tIter:66 train-loss:0.415965 valid-loss:1.105307  train-accuracy:0.946183 valid-accuracy:0.771739\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Make predictions","metadata":{}},{"cell_type":"markdown","source":"some debugging here","metadata":{}},{"cell_type":"code","source":"# #train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def,label=\"Survived\").map(Tokenize_names)\n# #serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_training_def).map(Tokenize_names)\n# serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(Tokenize_names)\n# proba_survived = model2.predict(serving_ds, verbose=0)\n# print(f\"proba survived shape : {proba_survived.shape}\")\n# proba_survived = proba_survived[:,0]\n# print(f\"proba survived shape : {proba_survived.shape}\")\n# print(f\"serving df shape : {serving_df.shape}\")\n# print(f\"serving df shape : {serving_ds.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:59:26.299710Z","iopub.execute_input":"2023-12-28T03:59:26.300129Z","iopub.status.idle":"2023-12-28T03:59:26.524193Z","shell.execute_reply.started":"2023-12-28T03:59:26.300094Z","shell.execute_reply":"2023-12-28T03:59:26.522962Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"proba survived shape : (418, 1)\nproba survived shape : (418,)\nserving df shape : (418, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"def prediction_to_kaggle_format(model, treshold = 0.5):\n    proba_survived = model.predict(serving_ds, verbose=0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\" : serving_df[\"PassengerId\"].values,\n        \"Survived\" : (proba_survived >= treshold).astype(int)\n    })\n\ndef make_submission(kaggle_predictions):\n    path = \"/kaggle/working/submission.csv\"\n    kaggle_predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n    \nkaggle_predictions = prediction_to_kaggle_format(model)\nmake_submission(kaggle_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:00:50.097198Z","iopub.execute_input":"2023-12-28T04:00:50.097786Z","iopub.status.idle":"2023-12-28T04:00:50.262895Z","shell.execute_reply.started":"2023-12-28T04:00:50.097734Z","shell.execute_reply":"2023-12-28T04:00:50.261711Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Submission exported to /kaggle/working/submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!head /kaggle/working/submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:04:40.800265Z","iopub.execute_input":"2023-12-28T04:04:40.800723Z","iopub.status.idle":"2023-12-28T04:04:41.983226Z","shell.execute_reply.started":"2023-12-28T04:04:40.800684Z","shell.execute_reply":"2023-12-28T04:04:41.981825Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"PassengerId,Survived\n892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training a model with hyperparameter tunning","metadata":{}},{"cell_type":"code","source":"# tunner = tfdf.tuner.RandomSearch(num_trials=1000)\n\n# tunner.choice(\"min_examples\",[2,5,7,10])\n# tunner.choice(\"categorical_algorithme\",[\"CART\",\"RANDOM\"])\n\n# local_search_space = tunner.choice(\"growing_strategy\",[\"LOCAL\"])\n# local_search_space.choice(\"max_depth\",[3,4,5,6,8])\n\n# local_search_space = tunner.choice(\"growing_strategy\",[\"BEST_FIRST_GLOBAL\"],merge=True)\n# local_search_space.choice(\"max_num_nodes\",[16,32,64,128,256])\n\n# tunner.choice(\"shrinkage\",[0.02,0.05,0.10,0.15])\n# tunner.choice(\"num_candidate_attributes_ration\",[0.2,0.5,0.9,1.0])\n\n# tunner.choice(\"split_axis\",[\"AXIS_ALIGNED\"])\n# oblique_space = tunner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\n\n# oblique_space.choice = (\"sparse_oblique_normalization\", [\"NONE\", \"STANDARD_DEVIATION\",\"MIN_MAX\"])\n# oblique_space.choice = (\"sparse_oblique_weights\", [\"BINARY\",\"CONTINUOUS\"])\n# oblique_space.choice = (\"sparse_oblique_num_projections_exponent\",[1.0,1.5])\n\n# tuned_model =tfdf.keras.GradientBoostedTreesModel(tuner=tunner)\n# tuned_model.fit(train_ds, verbose=0)\n\n# tuned_self_evaluation = tuned_model.make_inspector().evaluation()\n# print(f\"Accuracy{tuned_self_evaluation.accuracy}, Loss {tuned_self_evaluation.loss} \")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T04:04:20.689398Z","iopub.execute_input":"2023-12-28T04:04:20.689798Z","iopub.status.idle":"2023-12-28T04:04:20.696144Z","shell.execute_reply.started":"2023-12-28T04:04:20.689761Z","shell.execute_reply":"2023-12-28T04:04:20.694881Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"# Making an ensemble","metadata":{}},{"cell_type":"code","source":"# predictions = None\n# num_predictions = 0\n\n# for i in range (100):\n#     print(f\"i: {i}\")\n#     model = tfdf.keras.GradientBoostedTreesModel(\n#         verbose = 0,\n#         features = [tfdf.keras.FeatureUsage(name = n) for n in input_features],\n#         exclude_non_specified_features = True,\n#         random_seed=i,\n#         honest=True\n#     )\n#     model.fit(train_ds)\n#     sub_predictions = model.predict(serving_ds, verbose=0)[:,0]\n#     if predictions is None:\n#         predictions += sub_predictions\n#         num_prediction += 1\n    \n# predictions /=num_predictions\n# kaggle_predictions = pd.DataFrame({\n#     \"PassengerId\":serving_df[\"PassengerId\"],\n#     \"Survived\":(predictions >= 0.5).astype(int)\n# })\n# make_submissions(kaggle_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T03:13:52.699972Z","iopub.status.idle":"2023-12-28T03:13:52.700441Z","shell.execute_reply.started":"2023-12-28T03:13:52.700202Z","shell.execute_reply":"2023-12-28T03:13:52.700222Z"},"trusted":true},"execution_count":null,"outputs":[]}]}